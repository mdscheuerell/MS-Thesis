PHE.all <- ggplot(data = data, aes(x = Year, y = PHE.mean, color = System)) +
geom_point(size = 3, alpha = 0.7) +
labs(title = "Phenylalanine (source) Signature Through Time",
x = "Year",
y = "PHE d15N") +
theme(axis.title = element_text(size = 15),
plot.title = element_text(size=16)) +
geom_vline(xintercept=1977, linetype ="dashed") +
geom_vline(xintercept=1998, linetype ="dashed") +
geom_smooth(aes(group=1)) +
facet_grid(. ~ Age, labeller = labeller(Age = c("2" = "Age 2", "3" = "Age 3")))
PHE.W <- ggplot(data = Wood, aes(x = Year, y = PHE.mean)) +
geom_point(size = 3, alpha = 0.7, color = "#619CFF") +
labs(title = "Wood",
x = "Year",
y = "PHE d15N") +
theme(axis.title = element_text(size = 15),
plot.title = element_text(size=16)) +
geom_vline(xintercept=1977, linetype ="dashed") +
geom_vline(xintercept=1998, linetype ="dashed") +
geom_smooth(aes(group=1))
PHE.K <- ggplot(data = Kvichak, aes(x = Year, y = PHE.mean)) +
geom_point(size = 3, alpha = 0.7, color = "#00BA38") +
labs(title = "Kvichak",
x = "Year",
y = "PHE d15N") +
theme(axis.title = element_text(size = 15),
plot.title = element_text(size=16)) +
geom_vline(xintercept=1977, linetype ="dashed") +
geom_vline(xintercept=1998, linetype ="dashed") +
geom_smooth(aes(group=1))
PHE.E <- ggplot(data = Egegik, aes(x = Year, y = PHE.mean)) +
geom_point(size = 3, alpha = 0.7, color = "#F8766D") +
labs(title = "Egegik",
x = "Year",
y = "PHE d15N") +
theme(axis.title = element_text(size = 15),
plot.title = element_text(size=16)) +
geom_vline(xintercept=1977, linetype ="dashed") +
geom_vline(xintercept=1998, linetype ="dashed") +
geom_smooth(aes(group=1))
ggarrange(PHE.all, PHE.W, PHE.K, PHE.E)
GLU.all <- ggplot(data = data, aes(x = Year, y = GLU.mean, color = System)) +
geom_point(size = 3, alpha = 0.7) +
labs(title = "Glutamic Acid (trophic) Signature Through Time",
x = "Year",
y = "GLU d15N") +
theme(axis.title = element_text(size = 15),
plot.title = element_text(size=16)) +
geom_vline(xintercept=1977, linetype ="dashed") +
geom_vline(xintercept=2005, linetype ="dashed") +
geom_smooth(aes(group=1))
GLU.W <- ggplot(data = Wood, aes(x = Year, y = GLU.mean)) +
geom_point(size = 3, alpha = 0.7, color = "#619CFF") +
labs(title = "Wood",
x = "Year",
y = "GLU d15N") +
theme(axis.title = element_text(size = 15),
plot.title = element_text(size=16)) +
geom_vline(xintercept=1977, linetype ="dashed") +
geom_vline(xintercept=1998, linetype ="dashed") +
geom_smooth(aes(group=1))
GLU.K <- ggplot(data = Kvichak, aes(x = Year, y = GLU.mean)) +
geom_point(size = 3, alpha = 0.7, color = "#00BA38") +
labs(title = "Kvichak",
x = "Year",
y = "GLU d15N") +
theme(axis.title = element_text(size = 15),
plot.title = element_text(size=16)) +
geom_vline(xintercept=1977, linetype ="dashed") +
geom_vline(xintercept=1998, linetype ="dashed") +
geom_smooth(aes(group=1))
GLU.E <- ggplot(data = Egegik, aes(x = Year, y = GLU.mean)) +
geom_point(size = 3, alpha = 0.7, color = "#F8766D") +
labs(title = "Egegik",
x = "Year",
y = "GLU d15N") +
theme(axis.title = element_text(size = 15),
plot.title = element_text(size=16)) +
geom_vline(xintercept=1977, linetype ="dashed") +
geom_vline(xintercept=1998, linetype ="dashed") +
geom_smooth(aes(group=1))
ggarrange(GLU.all, GLU.W, GLU.K, GLU.E)
trophic.all <- ggplot(data = data, aes(x = Year, y = Trophic.Position, color = System)) +
geom_point(size = 3, alpha = 0.7) +
labs(title = "Trophic Position",
x = "Year",
y = "Trophic Position") +
theme(axis.title = element_text(size = 15),
plot.title = element_text(size=16)) +
geom_vline(xintercept=1977, linetype ="dashed") +
geom_vline(xintercept=1998, linetype ="dashed") +
geom_smooth(aes(group=1))
trophic.W <- ggplot(data = Wood, aes(x = Year, y = Trophic.Position)) +
geom_point(size = 3, alpha = 0.7, color = "#619CFF") +
labs(title = "Wood",
x = "Year",
y = "Trophic Position") +
theme(axis.title = element_text(size = 15),
plot.title = element_text(size=16)) +
geom_vline(xintercept=1977, linetype ="dashed") +
geom_vline(xintercept=1998, linetype ="dashed") +
geom_smooth(aes(group=1))
trophic.K <- ggplot(data = Kvichak, aes(x = Year, y = Trophic.Position)) +
geom_point(size = 3, alpha = 0.7, color = "#00BA38") +
labs(title = "Kvichak",
x = "Year",
y = "Trophic Position") +
theme(axis.title = element_text(size = 15),
plot.title = element_text(size=16)) +
geom_vline(xintercept=1977, linetype ="dashed") +
geom_vline(xintercept=1998, linetype ="dashed") +
geom_smooth(aes(group=1))
trophic.E <- ggplot(data = Egegik, aes(x = Year, y = Trophic.Position)) +
geom_point(size = 3, alpha = 0.7, color = "#F8766D") +
labs(title = "Egegik",
x = "Year",
y = "Trophic Position") +
theme(axis.title = element_text(size = 15),
plot.title = element_text(size=16)) +
geom_vline(xintercept=1977, linetype ="dashed") +
geom_vline(xintercept=1998, linetype ="dashed") +
geom_smooth(aes(group=1))
ggarrange(trophic.all, trophic.W, trophic.K, trophic.E)
#age class histogram
ggplot(data=data, aes(x = Trophic.Position, fill = as.factor(Age), color = as.factor(Age))) +
geom_histogram(bins = 60, position = "identity") +
geom_density(aes(fill = as.factor(Age), color = as.factor(Age)), alpha = 0.5) +
scale_alpha_manual(values = c(0.2, 0.5)) +
labs(title = "Trophic Position at Ocean Age Class",
x = "Trophic Position",
y = "Frequency",
fill = "Ocean Age") +
guides(color = FALSE)
#trophic position across systems histogram
ggplot(data=data, aes(x = Trophic.Position, fill = System, color = System)) +
geom_histogram(bins = 60, alpha = 0.5, position = "identity") +
labs(title = "Trophic Position across system",
x = "Trophic Position",
y = "Frequency",
fill = "System") +
guides(color = FALSE)
PHE.all
GLU.all <- ggplot(data = data, aes(x = Year, y = GLU.mean, color = System)) +
geom_point(size = 3, alpha = 0.7) +
labs(title = "Glutamic Acid (trophic) Signature Through Time",
x = "Year",
y = "GLU d15N") +
theme(axis.title = element_text(size = 15),
plot.title = element_text(size=16)) +
geom_vline(xintercept=1977, linetype ="dashed") +
geom_vline(xintercept=2005, linetype ="dashed") +
geom_smooth(aes(group=1)) +
facet_grid(. ~ Age, labeller = labeller(Age = c("2" = "Age 2", "3" = "Age 3")))
GLU.all
trophic.all <- ggplot(data = data, aes(x = Year, y = Trophic.Position, color = System)) +
geom_point(size = 3, alpha = 0.7) +
labs(title = "Trophic Position",
x = "Year",
y = "Trophic Position") +
theme(axis.title = element_text(size = 15),
plot.title = element_text(size=16)) +
geom_vline(xintercept=1977, linetype ="dashed") +
geom_vline(xintercept=1998, linetype ="dashed") +
geom_smooth(aes(group=1))+
facet_grid(. ~ Age, labeller = labeller(Age = c("2" = "Age 2", "3" = "Age 3")))
trophic.all
#main graphs with trend line
PHE.all <- ggplot(data = data, aes(x = Year, y = PHE.mean, color = System)) +
geom_point(size = 3, alpha = 0.7) +
labs(title = "Phenylalanine (source) Signature Through Time",
x = "Year",
y = "PHE d15N") +
theme(axis.title = element_text(size = 15),
plot.title = element_text(size=16)) +
geom_vline(xintercept=1977, linetype ="dashed") +
geom_vline(xintercept=1998, linetype ="dashed") +
geom_smooth(aes(group=1)) +
facet_grid(. ~ Age, labeller = labeller(Age = c("2" = "Age 2", "3" = "Age 3")))
#this is an r script to do some basic data visualization of the cleaned data
#at this point the data should be drift corrected, compiled, and had all
#duplicates and replicates removed and averaged
rm(list =ls())
setwd("~/Documents/GitHub/CSIA_lab_work/data/final")
library(dplyr)
library(readr)
library(ggplot2)
library(ggpubr)
#read in the main data file
data <- read.csv(file="main.trophic.csv")
#scatter plot of year vs isotope signature
PHE.all <- ggplot(data = data, aes(Year, PHE.mean, color = System)) +
geom_point(size = 3, alpha = 0.7)
Wood <- data[data$System =="Wood",]
Kvichak <- data[data$System =="Kvichak",]
Egegik <- data[data$System =="Egegik",]
#plots of age vs isotope sig in the different river systems
ggplot(data = Wood, aes(Year, PHE.mean, color = as.character(Age))) +
geom_point(size = 3, alpha = 0.7)
ggplot(data = Kvichak, aes(Year, PHE.mean, color = as.character(Age))) +
geom_point(size = 3, alpha = 0.7)
ggplot(data = Egegik, aes(Year, PHE.mean, color = as.character(Age))) +
geom_point(size = 3, alpha = 0.7)
#main graphs with trend line
PHE.all <- ggplot(data = data, aes(x = Year, y = PHE.mean, color = System)) +
geom_point(size = 3, alpha = 0.7) +
labs(title = "Phenylalanine (source) Signature Through Time",
x = "Year",
y = "PHE d15N") +
theme(axis.title = element_text(size = 15),
plot.title = element_text(size=16)) +
geom_vline(xintercept=1977, linetype ="dashed") +
geom_vline(xintercept=1998, linetype ="dashed") +
geom_smooth(aes(group=1)) +
facet_grid(. ~ Age, labeller = labeller(Age = c("2" = "Age 2", "3" = "Age 3")))
PHE.W <- ggplot(data = Wood, aes(x = Year, y = PHE.mean)) +
geom_point(size = 3, alpha = 0.7, color = "#619CFF") +
labs(title = "Wood",
x = "Year",
y = "PHE d15N") +
theme(axis.title = element_text(size = 15),
plot.title = element_text(size=16)) +
geom_vline(xintercept=1977, linetype ="dashed") +
geom_vline(xintercept=1998, linetype ="dashed") +
geom_smooth(aes(group=1))
PHE.K <- ggplot(data = Kvichak, aes(x = Year, y = PHE.mean)) +
geom_point(size = 3, alpha = 0.7, color = "#00BA38") +
labs(title = "Kvichak",
x = "Year",
y = "PHE d15N") +
theme(axis.title = element_text(size = 15),
plot.title = element_text(size=16)) +
geom_vline(xintercept=1977, linetype ="dashed") +
geom_vline(xintercept=1998, linetype ="dashed") +
geom_smooth(aes(group=1))
PHE.E <- ggplot(data = Egegik, aes(x = Year, y = PHE.mean)) +
geom_point(size = 3, alpha = 0.7, color = "#F8766D") +
labs(title = "Egegik",
x = "Year",
y = "PHE d15N") +
theme(axis.title = element_text(size = 15),
plot.title = element_text(size=16)) +
geom_vline(xintercept=1977, linetype ="dashed") +
geom_vline(xintercept=1998, linetype ="dashed") +
geom_smooth(aes(group=1))
ggarrange(PHE.all, PHE.W, PHE.K, PHE.E)
rm(list = ls())
setwd("~/Documents/GitHub/CSIA_lab_work/data")
library(dplyr)
name <- c("Analysis", "ID1", "RT", "AreaAll", "d29N", "d15N", "AAID")
#This is the stable isotpe ratios of the internal and external standards.
# MAKE SURE THIS IS UP TO DATE BASED ON HEEL STANDARDS!!! These values are as of 01/23/2020.
#If your samples were esterified after 01/23/2020 these values should be verfied with the standard file on the HEEL drive
ALA <- -1.21
VAL <- 0.361
NOR <- 14.163
PHE <- -5.004
GLU <- -3.336
rm(list = ls())
setwd("~/Documents/GitHub/CSIA_lab_work/data")
library(dplyr)
name <- c("Analysis", "ID1", "RT", "AreaAll", "d29N", "d15N", "AAID")
#This is the stable isotpe ratios of the internal and external standards.
# MAKE SURE THIS IS UP TO DATE BASED ON HEEL STANDARDS!!! These values are as of 01/23/2020.
#If your samples were esterified after 01/23/2020 these values should be verfied with the standard file on the HEEL drive
ALA <- -1.21
VAL <- 0.361
NOR <- 14.163
PHE <- -5.004
GLU <- -3.336
#Reading in the .csv of the NACHO data file and setting the file name for your output file
data.1 <- SL.1 <- read.csv("cleaned/20231117_GHenry_CSIA.csv") #modify with name of your data file
colnames(data.1)<-name
file.name <- "outliers_removed/20231010_with_outliers.csv" #file name for output file including relative file path
#Reading in the .csv of the NACHO data file and setting the file name for your output file
data.1 <- SL.1 <- read.csv("cleaned/20231117_GHenry_CSIA.csv") #modify with name of your data file
colnames(data.1)<-name
file.name <- "with_outliers/20231010.csv" #file name for output file including relative file path
#### Correct to international standard of N air ####
#Calculations of offset values were done in R script "Correct_to_Nair.R"
#Three EA runs were looked at, the second was chosen as the most representative to base corrections off
#No linear relationship was found between offset and measured value so one average value
#will be applied to raw data
#The offset values were calculated as EA measured d15N - reference
offset <- mean(c(0.40160, 0.47160, 0.41725))
data.1$d15N.correct <- data.1$d15N - offset
View(data.1)
data.1STD <- subset(data.1, ID1=="5AA") #get only the standard data
AA <- unique(unlist(data.1STD$AAID)) #make a list of the AAs in the data
Intercept<-data.frame(Intercept=rep(NA,length(AA))) #initiate a dataframe for the intercepts of the linear model
for(i in 1:length(AA)){
data <- subset(data.1STD, AAID==AA[i])
Intercept[i,1]<- coef(summary(lm(as.numeric(d15N.correct)~as.numeric(Analysis), data=data)))[1,1]
}
Intercept #intercept values looped by aa
Slope<-data.frame(Slope=rep(NA,length(AA))) #initiate a dataframe for the slopes of the linear model
for(i in 1:length(AA)){
data <- subset(data.1STD, AAID==AA[i])
Slope[i,1]<- coef(summary(lm(as.numeric(d15N.correct)~as.numeric(Analysis), data=data)))[2,1]
}
Slope #slope values looped by aa
Coef<- data.frame(AA, Intercept, Slope) #creating a dataframe of the slope and intercepts values for each AA
actual <- ifelse(data.1$AAID=="NOR", NOR,
ifelse(data.1$AAID=="ALA", ALA,
ifelse(data.1$AAID=="VAL", VAL,
ifelse(data.1$AAID=="PHE", PHE,
ifelse(data.1$AAID=="GLU", GLU,0)))))
actual #check your data -- if there are 0s than you have an AA that is not included in the standard 12AA mix and the code will need
slope <- ifelse(data.1$AAID=="NOR", filter(Coef, AA=="NOR")[1,3],
ifelse(data.1$AAID=="ALA", filter(Coef, AA=="ALA")[1,3],
ifelse(data.1$AAID=="VAL", filter(Coef, AA=="VAL")[1,3],
ifelse(data.1$AAID=="GLU", filter(Coef, AA=="GLU")[1,3],
ifelse(data.1$AAID=="PHE", filter(Coef, AA=="PHE")[1,3], 0)))))
intercept <-   ifelse(data.1$AAID=="NOR", filter(Coef, AA=="NOR")[1,2],
ifelse(data.1$AAID=="ALA", filter(Coef, AA=="ALA")[1,2],
ifelse(data.1$AAID=="VAL", filter(Coef, AA=="VAL")[1,2],
ifelse(data.1$AAID=="GLU", filter(Coef, AA=="GLU")[1,2],
ifelse(data.1$AAID=="PHE", filter(Coef, AA=="PHE")[1,2], 0)))))
#####Applying Drift Correction####
difference <- actual-(data.1$Analysis*slope+intercept) #Applying both a drift and step correction in on estep from linear model data
adj <- data.1$d15N.correct + difference
data <- cbind(data.1, adj)
data
View(data)
AA<- unique(unlist(df$AAID)) #make a list of the AAs in the data
mean <- aggregate(df['adj'], by = list(df$ID1, df$AAID), mean)
AA<- unique(unlist(data$AAID)) #make a list of the AAs in the data
mean <- aggregate(df['adj'], by = list(df$ID1, df$AAID), mean)
mean_names <- c("Sample.ID",paste0(AA,".mean"))
mean <- aggregate(data['adj'], by = list(data$ID1, data$AAID), mean)
mean_names <- c("Sample.ID",paste0(AA,".mean"))
meanfull<-data.frame(matrix(0, nrow = length(unique(mean$Group.1)), ncol = length(AA)+1)) #initiate a dataframe for the intercepts of the linear model
colnames(meanfull) <- mean_names
meanfull[1:length(unique(mean$Group.1)),1]<- unique(mean$Group.1)
for(i in 1:length(AA)){
meanfull[1:length(unique(mean$Group.1)),i+1]<- mean%>%
filter(Group.2  == AA[i])%>%
select(adj)
}
meanfull #ALWAYS check to make sure everything looks right! small errors can break the code
sd<- aggregate(data['adj'], by = list(data$ID1, data$AAID), sd)
sd_names <- c("Sample.ID",paste0(AA,".sd"))
sdfull<-data.frame(matrix(0, nrow = length(unique(sd$Group.1)), ncol = length(AA)+1))
colnames(sdfull)<- sd_names
sdfull[1:length(unique(sd$Group.1)),1]<- unique(sd$Group.1)
for(i in 1:length(AA)){
sdfull[1:length(unique(sd$Group.1)),i+1]<- sd%>%
filter(Group.2  == AA[i])%>%
select(adj)
}
sdfull
Corrected <- merge(meanfull,sdfull, by="Sample.ID") #this merges the columns in both the SD and mean dataframes
Corrected
View(Corrected)
##### Write new .csv file ####
write.csv(Corrected, file = file.name)
#Reading in the .csv of the NACHO data file and setting the file name for your output file
data.1 <- SL.1 <- read.csv("cleaned/20231116_GHenry_CSIA.csv") #modify with name of your data file
#Reading in the .csv of the NACHO data file and setting the file name for your output file
data.1 <- SL.1 <- read.csv("cleaned/20231117_GHenry_CSIA.csv") #modify with name of your data file
#Reading in the .csv of the NACHO data file and setting the file name for your output file
data.1 <- SL.1 <- read.csv("cleaned/20231117_GHenry_CSIA.csv") #modify with name of your data file
colnames(data.1)<-name
file.name <- "with_outliers/20231117.csv" #file name for output file including relative file path
#### Correct to international standard of N air ####
#Calculations of offset values were done in R script "Correct_to_Nair.R"
#Three EA runs were looked at, the second was chosen as the most representative to base corrections off
#No linear relationship was found between offset and measured value so one average value
#will be applied to raw data
#The offset values were calculated as EA measured d15N - reference
offset <- mean(c(0.40160, 0.47160, 0.41725))
data.1$d15N.correct <- data.1$d15N - offset
data.1STD <- subset(data.1, ID1=="5AA") #get only the standard data
AA <- unique(unlist(data.1STD$AAID)) #make a list of the AAs in the data
Intercept<-data.frame(Intercept=rep(NA,length(AA))) #initiate a dataframe for the intercepts of the linear model
for(i in 1:length(AA)){
data <- subset(data.1STD, AAID==AA[i])
Intercept[i,1]<- coef(summary(lm(as.numeric(d15N.correct)~as.numeric(Analysis), data=data)))[1,1]
}
Intercept #intercept values looped by aa
Slope<-data.frame(Slope=rep(NA,length(AA))) #initiate a dataframe for the slopes of the linear model
for(i in 1:length(AA)){
data <- subset(data.1STD, AAID==AA[i])
Slope[i,1]<- coef(summary(lm(as.numeric(d15N.correct)~as.numeric(Analysis), data=data)))[2,1]
}
Slope #slope values looped by aa
Coef<- data.frame(AA, Intercept, Slope) #creating a dataframe of the slope and intercepts values for each AA
actual <- ifelse(data.1$AAID=="NOR", NOR,
ifelse(data.1$AAID=="ALA", ALA,
ifelse(data.1$AAID=="VAL", VAL,
ifelse(data.1$AAID=="PHE", PHE,
ifelse(data.1$AAID=="GLU", GLU,0)))))
actual #check your data -- if there are 0s than you have an AA that is not included in the standard 12AA mix and the code will need
slope <- ifelse(data.1$AAID=="NOR", filter(Coef, AA=="NOR")[1,3],
ifelse(data.1$AAID=="ALA", filter(Coef, AA=="ALA")[1,3],
ifelse(data.1$AAID=="VAL", filter(Coef, AA=="VAL")[1,3],
ifelse(data.1$AAID=="GLU", filter(Coef, AA=="GLU")[1,3],
ifelse(data.1$AAID=="PHE", filter(Coef, AA=="PHE")[1,3], 0)))))
intercept <-   ifelse(data.1$AAID=="NOR", filter(Coef, AA=="NOR")[1,2],
ifelse(data.1$AAID=="ALA", filter(Coef, AA=="ALA")[1,2],
ifelse(data.1$AAID=="VAL", filter(Coef, AA=="VAL")[1,2],
ifelse(data.1$AAID=="GLU", filter(Coef, AA=="GLU")[1,2],
ifelse(data.1$AAID=="PHE", filter(Coef, AA=="PHE")[1,2], 0)))))
#####Applying Drift Correction####
difference <- actual-(data.1$Analysis*slope+intercept) #Applying both a drift and step correction in on estep from linear model data
adj <- data.1$d15N.correct + difference
data <- cbind(data.1, adj)
data
AA<- unique(unlist(data$AAID)) #make a list of the AAs in the data
mean <- aggregate(data['adj'], by = list(data$ID1, data$AAID), mean)
mean_names <- c("Sample.ID",paste0(AA,".mean"))
meanfull<-data.frame(matrix(0, nrow = length(unique(mean$Group.1)), ncol = length(AA)+1)) #initiate a dataframe for the intercepts of the linear model
colnames(meanfull) <- mean_names
meanfull[1:length(unique(mean$Group.1)),1]<- unique(mean$Group.1)
for(i in 1:length(AA)){
meanfull[1:length(unique(mean$Group.1)),i+1]<- mean%>%
filter(Group.2  == AA[i])%>%
select(adj)
}
meanfull #ALWAYS check to make sure everything looks right! small errors can break the code
sd<- aggregate(data['adj'], by = list(data$ID1, data$AAID), sd)
sd_names <- c("Sample.ID",paste0(AA,".sd"))
sdfull<-data.frame(matrix(0, nrow = length(unique(sd$Group.1)), ncol = length(AA)+1))
colnames(sdfull)<- sd_names
sdfull[1:length(unique(sd$Group.1)),1]<- unique(sd$Group.1)
for(i in 1:length(AA)){
sdfull[1:length(unique(sd$Group.1)),i+1]<- sd%>%
filter(Group.2  == AA[i])%>%
select(adj)
}
sdfull
Corrected <- merge(meanfull,sdfull, by="Sample.ID") #this merges the columns in both the SD and mean dataframes
Corrected
##### Write new .csv file ####
write.csv(Corrected, file = file.name)
View(Corrected)
#Reading in the .csv of the NACHO data file and setting the file name for your output file
data.1 <- SL.1 <- read.csv("cleaned/20231116_GHenry_CSIA.csv") #modify with name of your data file
colnames(data.1)<-name
file.name <- "with_outliers/20231116.csv" #file name for output file including relative file path
#### Correct to international standard of N air ####
#Calculations of offset values were done in R script "Correct_to_Nair.R"
#Three EA runs were looked at, the second was chosen as the most representative to base corrections off
#No linear relationship was found between offset and measured value so one average value
#will be applied to raw data
#The offset values were calculated as EA measured d15N - reference
offset <- mean(c(0.40160, 0.47160, 0.41725))
data.1$d15N.correct <- data.1$d15N - offset
data.1STD <- subset(data.1, ID1=="5AA") #get only the standard data
AA <- unique(unlist(data.1STD$AAID)) #make a list of the AAs in the data
Intercept<-data.frame(Intercept=rep(NA,length(AA))) #initiate a dataframe for the intercepts of the linear model
for(i in 1:length(AA)){
data <- subset(data.1STD, AAID==AA[i])
Intercept[i,1]<- coef(summary(lm(as.numeric(d15N.correct)~as.numeric(Analysis), data=data)))[1,1]
}
Intercept #intercept values looped by aa
Slope<-data.frame(Slope=rep(NA,length(AA))) #initiate a dataframe for the slopes of the linear model
for(i in 1:length(AA)){
data <- subset(data.1STD, AAID==AA[i])
Slope[i,1]<- coef(summary(lm(as.numeric(d15N.correct)~as.numeric(Analysis), data=data)))[2,1]
}
Slope #slope values looped by aa
Coef<- data.frame(AA, Intercept, Slope) #creating a dataframe of the slope and intercepts values for each AA
actual <- ifelse(data.1$AAID=="NOR", NOR,
ifelse(data.1$AAID=="ALA", ALA,
ifelse(data.1$AAID=="VAL", VAL,
ifelse(data.1$AAID=="PHE", PHE,
ifelse(data.1$AAID=="GLU", GLU,0)))))
actual #check your data -- if there are 0s than you have an AA that is not included in the standard 12AA mix and the code will need
slope <- ifelse(data.1$AAID=="NOR", filter(Coef, AA=="NOR")[1,3],
ifelse(data.1$AAID=="ALA", filter(Coef, AA=="ALA")[1,3],
ifelse(data.1$AAID=="VAL", filter(Coef, AA=="VAL")[1,3],
ifelse(data.1$AAID=="GLU", filter(Coef, AA=="GLU")[1,3],
ifelse(data.1$AAID=="PHE", filter(Coef, AA=="PHE")[1,3], 0)))))
intercept <-   ifelse(data.1$AAID=="NOR", filter(Coef, AA=="NOR")[1,2],
ifelse(data.1$AAID=="ALA", filter(Coef, AA=="ALA")[1,2],
ifelse(data.1$AAID=="VAL", filter(Coef, AA=="VAL")[1,2],
ifelse(data.1$AAID=="GLU", filter(Coef, AA=="GLU")[1,2],
ifelse(data.1$AAID=="PHE", filter(Coef, AA=="PHE")[1,2], 0)))))
#####Applying Drift Correction####
difference <- actual-(data.1$Analysis*slope+intercept) #Applying both a drift and step correction in on estep from linear model data
adj <- data.1$d15N.correct + difference
data <- cbind(data.1, adj)
data
AA<- unique(unlist(data$AAID)) #make a list of the AAs in the data
mean <- aggregate(data['adj'], by = list(data$ID1, data$AAID), mean)
mean_names <- c("Sample.ID",paste0(AA,".mean"))
meanfull<-data.frame(matrix(0, nrow = length(unique(mean$Group.1)), ncol = length(AA)+1)) #initiate a dataframe for the intercepts of the linear model
colnames(meanfull) <- mean_names
meanfull[1:length(unique(mean$Group.1)),1]<- unique(mean$Group.1)
for(i in 1:length(AA)){
meanfull[1:length(unique(mean$Group.1)),i+1]<- mean%>%
filter(Group.2  == AA[i])%>%
select(adj)
}
meanfull #ALWAYS check to make sure everything looks right! small errors can break the code
sd<- aggregate(data['adj'], by = list(data$ID1, data$AAID), sd)
sd_names <- c("Sample.ID",paste0(AA,".sd"))
sdfull<-data.frame(matrix(0, nrow = length(unique(sd$Group.1)), ncol = length(AA)+1))
colnames(sdfull)<- sd_names
sdfull[1:length(unique(sd$Group.1)),1]<- unique(sd$Group.1)
for(i in 1:length(AA)){
sdfull[1:length(unique(sd$Group.1)),i+1]<- sd%>%
filter(Group.2  == AA[i])%>%
select(adj)
}
sdfull
Corrected <- merge(meanfull,sdfull, by="Sample.ID") #this merges the columns in both the SD and mean dataframes
Corrected
View(Corrected)
##### Write new .csv file ####
write.csv(Corrected, file = file.name)
