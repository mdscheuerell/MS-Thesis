meanfull[1:length(unique(mean$Group.1)),i+1]<- mean%>%
filter(Group.2  == AA[i])%>%
select(adj)
}
meanfull #ALWAYS check to make sure everything looks right! small errors can break the code
sd<- aggregate(data['adj'], by = list(data$ID1, data$AAID), sd)
sd_names <- c("Sample.ID",paste0(AA,".sd"))
sdfull<-data.frame(matrix(0, nrow = length(unique(sd$Group.1)), ncol = length(AA)+1))
colnames(sdfull)<- sd_names
sdfull[1:length(unique(sd$Group.1)),1]<- unique(sd$Group.1)
for(i in 1:length(AA)){
sdfull[1:length(unique(sd$Group.1)),i+1]<- sd%>%
filter(Group.2  == AA[i])%>%
select(adj)
}
sdfull
Corrected <- merge(meanfull,sdfull, by="Sample.ID") #this merges the columns in both the SD and mean dataframes
Corrected
##### Write new .csv file ####
write.csv(Corrected, file = file.name)
#Reading in the .csv of the NACHO data file and setting the file name for your output file
data.1 <- SL.1 <- read.csv("cleaned/20230901_GHenry_CSIA.csv") #modify with name of your data file
colnames(data.1)<-name
file.name <- "with_outliers/20230901.csv" #file name for output file including relative file path
#### Correct to international standard of N air ####
#Calculations of offset values were done in R script "Correct_to_Nair.R"
#Three EA runs were looked at, the second was chosen as the most representative to base corrections off
#No linear relationship was found between offset and measured value so one average value
#will be applied to raw data
#The offset values were calculated as EA measured d15N - reference
offset <- mean(c(0.40160, 0.47160, 0.41725))
data.1$d15N.correct <- data.1$d15N - offset
data.1STD <- subset(data.1, ID1=="5AA") #get only the standard data
AA <- unique(unlist(data.1STD$AAID)) #make a list of the AAs in the data
Intercept<-data.frame(Intercept=rep(NA,length(AA))) #initiate a dataframe for the intercepts of the linear model
for(i in 1:length(AA)){
data <- subset(data.1STD, AAID==AA[i])
Intercept[i,1]<- coef(summary(lm(as.numeric(d15N.correct)~as.numeric(Analysis), data=data)))[1,1]
}
Intercept #intercept values looped by aa
Slope<-data.frame(Slope=rep(NA,length(AA))) #initiate a dataframe for the slopes of the linear model
for(i in 1:length(AA)){
data <- subset(data.1STD, AAID==AA[i])
Slope[i,1]<- coef(summary(lm(as.numeric(d15N.correct)~as.numeric(Analysis), data=data)))[2,1]
}
Slope #slope values looped by aa
Coef<- data.frame(AA, Intercept, Slope) #creating a dataframe of the slope and intercepts values for each AA
actual <- ifelse(data.1$AAID=="NOR", NOR,
ifelse(data.1$AAID=="ALA", ALA,
ifelse(data.1$AAID=="VAL", VAL,
ifelse(data.1$AAID=="PHE", PHE,
ifelse(data.1$AAID=="GLU", GLU,0)))))
actual #check your data -- if there are 0s than you have an AA that is not included in the standard 12AA mix and the code will need
slope <- ifelse(data.1$AAID=="NOR", filter(Coef, AA=="NOR")[1,3],
ifelse(data.1$AAID=="ALA", filter(Coef, AA=="ALA")[1,3],
ifelse(data.1$AAID=="VAL", filter(Coef, AA=="VAL")[1,3],
ifelse(data.1$AAID=="GLU", filter(Coef, AA=="GLU")[1,3],
ifelse(data.1$AAID=="PHE", filter(Coef, AA=="PHE")[1,3], 0)))))
intercept <-   ifelse(data.1$AAID=="NOR", filter(Coef, AA=="NOR")[1,2],
ifelse(data.1$AAID=="ALA", filter(Coef, AA=="ALA")[1,2],
ifelse(data.1$AAID=="VAL", filter(Coef, AA=="VAL")[1,2],
ifelse(data.1$AAID=="GLU", filter(Coef, AA=="GLU")[1,2],
ifelse(data.1$AAID=="PHE", filter(Coef, AA=="PHE")[1,2], 0)))))
#####Applying Drift Correction####
difference <- actual-(data.1$Analysis*slope+intercept) #Applying both a drift and step correction in on estep from linear model data
adj <- data.1$d15N.correct + difference
data <- cbind(data.1, adj)
data
AA<- unique(unlist(data$AAID)) #make a list of the AAs in the data
mean <- aggregate(data['adj'], by = list(data$ID1, data$AAID), mean)
mean_names <- c("Sample.ID",paste0(AA,".mean"))
meanfull<-data.frame(matrix(0, nrow = length(unique(mean$Group.1)), ncol = length(AA)+1)) #initiate a dataframe for the intercepts of the linear model
colnames(meanfull) <- mean_names
meanfull[1:length(unique(mean$Group.1)),1]<- unique(mean$Group.1)
for(i in 1:length(AA)){
meanfull[1:length(unique(mean$Group.1)),i+1]<- mean%>%
filter(Group.2  == AA[i])%>%
select(adj)
}
meanfull #ALWAYS check to make sure everything looks right! small errors can break the code
sd<- aggregate(data['adj'], by = list(data$ID1, data$AAID), sd)
sd_names <- c("Sample.ID",paste0(AA,".sd"))
sdfull<-data.frame(matrix(0, nrow = length(unique(sd$Group.1)), ncol = length(AA)+1))
colnames(sdfull)<- sd_names
sdfull[1:length(unique(sd$Group.1)),1]<- unique(sd$Group.1)
for(i in 1:length(AA)){
sdfull[1:length(unique(sd$Group.1)),i+1]<- sd%>%
filter(Group.2  == AA[i])%>%
select(adj)
}
sdfull
Corrected <- merge(meanfull,sdfull, by="Sample.ID") #this merges the columns in both the SD and mean dataframes
Corrected
##### Write new .csv file ####
write.csv(Corrected, file = file.name)
#Reading in the .csv of the NACHO data file and setting the file name for your output file
data.1 <- SL.1 <- read.csv("cleaned/20230824_GHenry_CSIA.csv") #modify with name of your data file
colnames(data.1)<-name
file.name <- "with_outliers/20230824.csv" #file name for output file including relative file path
#### Correct to international standard of N air ####
#Calculations of offset values were done in R script "Correct_to_Nair.R"
#Three EA runs were looked at, the second was chosen as the most representative to base corrections off
#No linear relationship was found between offset and measured value so one average value
#will be applied to raw data
#The offset values were calculated as EA measured d15N - reference
offset <- mean(c(0.40160, 0.47160, 0.41725))
data.1$d15N.correct <- data.1$d15N - offset
data.1STD <- subset(data.1, ID1=="5AA") #get only the standard data
AA <- unique(unlist(data.1STD$AAID)) #make a list of the AAs in the data
Intercept<-data.frame(Intercept=rep(NA,length(AA))) #initiate a dataframe for the intercepts of the linear model
for(i in 1:length(AA)){
data <- subset(data.1STD, AAID==AA[i])
Intercept[i,1]<- coef(summary(lm(as.numeric(d15N.correct)~as.numeric(Analysis), data=data)))[1,1]
}
Intercept #intercept values looped by aa
Slope<-data.frame(Slope=rep(NA,length(AA))) #initiate a dataframe for the slopes of the linear model
for(i in 1:length(AA)){
data <- subset(data.1STD, AAID==AA[i])
Slope[i,1]<- coef(summary(lm(as.numeric(d15N.correct)~as.numeric(Analysis), data=data)))[2,1]
}
Slope #slope values looped by aa
Coef<- data.frame(AA, Intercept, Slope) #creating a dataframe of the slope and intercepts values for each AA
actual <- ifelse(data.1$AAID=="NOR", NOR,
ifelse(data.1$AAID=="ALA", ALA,
ifelse(data.1$AAID=="VAL", VAL,
ifelse(data.1$AAID=="PHE", PHE,
ifelse(data.1$AAID=="GLU", GLU,0)))))
actual #check your data -- if there are 0s than you have an AA that is not included in the standard 12AA mix and the code will need
slope <- ifelse(data.1$AAID=="NOR", filter(Coef, AA=="NOR")[1,3],
ifelse(data.1$AAID=="ALA", filter(Coef, AA=="ALA")[1,3],
ifelse(data.1$AAID=="VAL", filter(Coef, AA=="VAL")[1,3],
ifelse(data.1$AAID=="GLU", filter(Coef, AA=="GLU")[1,3],
ifelse(data.1$AAID=="PHE", filter(Coef, AA=="PHE")[1,3], 0)))))
intercept <-   ifelse(data.1$AAID=="NOR", filter(Coef, AA=="NOR")[1,2],
ifelse(data.1$AAID=="ALA", filter(Coef, AA=="ALA")[1,2],
ifelse(data.1$AAID=="VAL", filter(Coef, AA=="VAL")[1,2],
ifelse(data.1$AAID=="GLU", filter(Coef, AA=="GLU")[1,2],
ifelse(data.1$AAID=="PHE", filter(Coef, AA=="PHE")[1,2], 0)))))
#####Applying Drift Correction####
difference <- actual-(data.1$Analysis*slope+intercept) #Applying both a drift and step correction in on estep from linear model data
adj <- data.1$d15N.correct + difference
data <- cbind(data.1, adj)
data
AA<- unique(unlist(data$AAID)) #make a list of the AAs in the data
mean <- aggregate(data['adj'], by = list(data$ID1, data$AAID), mean)
mean_names <- c("Sample.ID",paste0(AA,".mean"))
meanfull<-data.frame(matrix(0, nrow = length(unique(mean$Group.1)), ncol = length(AA)+1)) #initiate a dataframe for the intercepts of the linear model
colnames(meanfull) <- mean_names
meanfull[1:length(unique(mean$Group.1)),1]<- unique(mean$Group.1)
for(i in 1:length(AA)){
meanfull[1:length(unique(mean$Group.1)),i+1]<- mean%>%
filter(Group.2  == AA[i])%>%
select(adj)
}
meanfull #ALWAYS check to make sure everything looks right! small errors can break the code
sd<- aggregate(data['adj'], by = list(data$ID1, data$AAID), sd)
sd_names <- c("Sample.ID",paste0(AA,".sd"))
sdfull<-data.frame(matrix(0, nrow = length(unique(sd$Group.1)), ncol = length(AA)+1))
colnames(sdfull)<- sd_names
sdfull[1:length(unique(sd$Group.1)),1]<- unique(sd$Group.1)
for(i in 1:length(AA)){
sdfull[1:length(unique(sd$Group.1)),i+1]<- sd%>%
filter(Group.2  == AA[i])%>%
select(adj)
}
sdfull
Corrected <- merge(meanfull,sdfull, by="Sample.ID") #this merges the columns in both the SD and mean dataframes
Corrected
##### Write new .csv file ####
write.csv(Corrected, file = file.name)
#Reading in the .csv of the NACHO data file and setting the file name for your output file
data.1 <- SL.1 <- read.csv("cleaned/20231010_GHenry_CSIA.csv") #modify with name of your data file
colnames(data.1)<-name
file.name <- "with_outliers/20231010.csv" #file name for output file including relative file path
#### Correct to international standard of N air ####
#Calculations of offset values were done in R script "Correct_to_Nair.R"
#Three EA runs were looked at, the second was chosen as the most representative to base corrections off
#No linear relationship was found between offset and measured value so one average value
#will be applied to raw data
#The offset values were calculated as EA measured d15N - reference
offset <- mean(c(0.40160, 0.47160, 0.41725))
data.1$d15N.correct <- data.1$d15N - offset
data.1STD <- subset(data.1, ID1=="5AA") #get only the standard data
AA <- unique(unlist(data.1STD$AAID)) #make a list of the AAs in the data
Intercept<-data.frame(Intercept=rep(NA,length(AA))) #initiate a dataframe for the intercepts of the linear model
for(i in 1:length(AA)){
data <- subset(data.1STD, AAID==AA[i])
Intercept[i,1]<- coef(summary(lm(as.numeric(d15N.correct)~as.numeric(Analysis), data=data)))[1,1]
}
Intercept #intercept values looped by aa
Slope<-data.frame(Slope=rep(NA,length(AA))) #initiate a dataframe for the slopes of the linear model
for(i in 1:length(AA)){
data <- subset(data.1STD, AAID==AA[i])
Slope[i,1]<- coef(summary(lm(as.numeric(d15N.correct)~as.numeric(Analysis), data=data)))[2,1]
}
Slope #slope values looped by aa
Coef<- data.frame(AA, Intercept, Slope) #creating a dataframe of the slope and intercepts values for each AA
actual <- ifelse(data.1$AAID=="NOR", NOR,
ifelse(data.1$AAID=="ALA", ALA,
ifelse(data.1$AAID=="VAL", VAL,
ifelse(data.1$AAID=="PHE", PHE,
ifelse(data.1$AAID=="GLU", GLU,0)))))
actual #check your data -- if there are 0s than you have an AA that is not included in the standard 12AA mix and the code will need
slope <- ifelse(data.1$AAID=="NOR", filter(Coef, AA=="NOR")[1,3],
ifelse(data.1$AAID=="ALA", filter(Coef, AA=="ALA")[1,3],
ifelse(data.1$AAID=="VAL", filter(Coef, AA=="VAL")[1,3],
ifelse(data.1$AAID=="GLU", filter(Coef, AA=="GLU")[1,3],
ifelse(data.1$AAID=="PHE", filter(Coef, AA=="PHE")[1,3], 0)))))
intercept <-   ifelse(data.1$AAID=="NOR", filter(Coef, AA=="NOR")[1,2],
ifelse(data.1$AAID=="ALA", filter(Coef, AA=="ALA")[1,2],
ifelse(data.1$AAID=="VAL", filter(Coef, AA=="VAL")[1,2],
ifelse(data.1$AAID=="GLU", filter(Coef, AA=="GLU")[1,2],
ifelse(data.1$AAID=="PHE", filter(Coef, AA=="PHE")[1,2], 0)))))
#####Applying Drift Correction####
difference <- actual-(data.1$Analysis*slope+intercept) #Applying both a drift and step correction in on estep from linear model data
adj <- data.1$d15N.correct + difference
data <- cbind(data.1, adj)
data
AA<- unique(unlist(data$AAID)) #make a list of the AAs in the data
mean <- aggregate(data['adj'], by = list(data$ID1, data$AAID), mean)
mean_names <- c("Sample.ID",paste0(AA,".mean"))
meanfull<-data.frame(matrix(0, nrow = length(unique(mean$Group.1)), ncol = length(AA)+1)) #initiate a dataframe for the intercepts of the linear model
colnames(meanfull) <- mean_names
meanfull[1:length(unique(mean$Group.1)),1]<- unique(mean$Group.1)
for(i in 1:length(AA)){
meanfull[1:length(unique(mean$Group.1)),i+1]<- mean%>%
filter(Group.2  == AA[i])%>%
select(adj)
}
meanfull #ALWAYS check to make sure everything looks right! small errors can break the code
sd<- aggregate(data['adj'], by = list(data$ID1, data$AAID), sd)
sd_names <- c("Sample.ID",paste0(AA,".sd"))
sdfull<-data.frame(matrix(0, nrow = length(unique(sd$Group.1)), ncol = length(AA)+1))
colnames(sdfull)<- sd_names
sdfull[1:length(unique(sd$Group.1)),1]<- unique(sd$Group.1)
for(i in 1:length(AA)){
sdfull[1:length(unique(sd$Group.1)),i+1]<- sd%>%
filter(Group.2  == AA[i])%>%
select(adj)
}
sdfull
Corrected <- merge(meanfull,sdfull, by="Sample.ID") #this merges the columns in both the SD and mean dataframes
Corrected
##### Write new .csv file ####
write.csv(Corrected, file = file.name)
#Reading in the .csv of the NACHO data file and setting the file name for your output file
data.1 <- SL.1 <- read.csv("cleaned/20231013_GHenry_CSIA.csv") #modify with name of your data file
colnames(data.1)<-name
file.name <- "with_outliers/20231013.csv" #file name for output file including relative file path
#### Correct to international standard of N air ####
#Calculations of offset values were done in R script "Correct_to_Nair.R"
#Three EA runs were looked at, the second was chosen as the most representative to base corrections off
#No linear relationship was found between offset and measured value so one average value
#will be applied to raw data
#The offset values were calculated as EA measured d15N - reference
offset <- mean(c(0.40160, 0.47160, 0.41725))
data.1$d15N.correct <- data.1$d15N - offset
data.1STD <- subset(data.1, ID1=="5AA") #get only the standard data
AA <- unique(unlist(data.1STD$AAID)) #make a list of the AAs in the data
Intercept<-data.frame(Intercept=rep(NA,length(AA))) #initiate a dataframe for the intercepts of the linear model
for(i in 1:length(AA)){
data <- subset(data.1STD, AAID==AA[i])
Intercept[i,1]<- coef(summary(lm(as.numeric(d15N.correct)~as.numeric(Analysis), data=data)))[1,1]
}
Intercept #intercept values looped by aa
Slope<-data.frame(Slope=rep(NA,length(AA))) #initiate a dataframe for the slopes of the linear model
for(i in 1:length(AA)){
data <- subset(data.1STD, AAID==AA[i])
Slope[i,1]<- coef(summary(lm(as.numeric(d15N.correct)~as.numeric(Analysis), data=data)))[2,1]
}
Slope #slope values looped by aa
Coef<- data.frame(AA, Intercept, Slope) #creating a dataframe of the slope and intercepts values for each AA
actual <- ifelse(data.1$AAID=="NOR", NOR,
ifelse(data.1$AAID=="ALA", ALA,
ifelse(data.1$AAID=="VAL", VAL,
ifelse(data.1$AAID=="PHE", PHE,
ifelse(data.1$AAID=="GLU", GLU,0)))))
actual #check your data -- if there are 0s than you have an AA that is not included in the standard 12AA mix and the code will need
slope <- ifelse(data.1$AAID=="NOR", filter(Coef, AA=="NOR")[1,3],
ifelse(data.1$AAID=="ALA", filter(Coef, AA=="ALA")[1,3],
ifelse(data.1$AAID=="VAL", filter(Coef, AA=="VAL")[1,3],
ifelse(data.1$AAID=="GLU", filter(Coef, AA=="GLU")[1,3],
ifelse(data.1$AAID=="PHE", filter(Coef, AA=="PHE")[1,3], 0)))))
intercept <-   ifelse(data.1$AAID=="NOR", filter(Coef, AA=="NOR")[1,2],
ifelse(data.1$AAID=="ALA", filter(Coef, AA=="ALA")[1,2],
ifelse(data.1$AAID=="VAL", filter(Coef, AA=="VAL")[1,2],
ifelse(data.1$AAID=="GLU", filter(Coef, AA=="GLU")[1,2],
ifelse(data.1$AAID=="PHE", filter(Coef, AA=="PHE")[1,2], 0)))))
#####Applying Drift Correction####
difference <- actual-(data.1$Analysis*slope+intercept) #Applying both a drift and step correction in on estep from linear model data
adj <- data.1$d15N.correct + difference
data <- cbind(data.1, adj)
data
AA<- unique(unlist(data$AAID)) #make a list of the AAs in the data
mean <- aggregate(data['adj'], by = list(data$ID1, data$AAID), mean)
mean_names <- c("Sample.ID",paste0(AA,".mean"))
meanfull<-data.frame(matrix(0, nrow = length(unique(mean$Group.1)), ncol = length(AA)+1)) #initiate a dataframe for the intercepts of the linear model
colnames(meanfull) <- mean_names
meanfull[1:length(unique(mean$Group.1)),1]<- unique(mean$Group.1)
for(i in 1:length(AA)){
meanfull[1:length(unique(mean$Group.1)),i+1]<- mean%>%
filter(Group.2  == AA[i])%>%
select(adj)
}
meanfull #ALWAYS check to make sure everything looks right! small errors can break the code
sd<- aggregate(data['adj'], by = list(data$ID1, data$AAID), sd)
sd_names <- c("Sample.ID",paste0(AA,".sd"))
sdfull<-data.frame(matrix(0, nrow = length(unique(sd$Group.1)), ncol = length(AA)+1))
colnames(sdfull)<- sd_names
sdfull[1:length(unique(sd$Group.1)),1]<- unique(sd$Group.1)
for(i in 1:length(AA)){
sdfull[1:length(unique(sd$Group.1)),i+1]<- sd%>%
filter(Group.2  == AA[i])%>%
select(adj)
}
sdfull
Corrected <- merge(meanfull,sdfull, by="Sample.ID") #this merges the columns in both the SD and mean dataframes
Corrected
##### Write new .csv file ####
write.csv(Corrected, file = file.name)
#this script should be run after drift correcting and removing outliers
#from each individual run using the DriftCorrection_outliers.R script
setwd("~/Documents/GitHub/CSIA_lab_work/data")
rm(list = ls())
library(dplyr)
library(readr)
#compile all the csv files to make one dataframe of all data
df <- list.files(path=setwd("~/Documents/GitHub/CSIA_lab_work/data/with_outliers")) %>%
lapply(read_csv) %>%
bind_rows
#compile all the csv files to make one dataframe of all data
df <- list.files(path=setwd("~/Documents/GitHub/CSIA_lab_work/data/with_outliers")) %>%
lapply(read_csv) %>%
bind_rows
df <- df[!df$AAID == "REF",]
View(df)
AA<- unique(unlist(df$AAID)) #make a list of the AAs in the data
View(df)
setwd("~/Documents/GitHub/CSIA_lab_work/data")
rm(list = ls())
library(dplyr)
library(readr)
#compile all the csv files to make one dataframe of all data
df <- list.files(path=setwd("~/Documents/GitHub/CSIA_lab_work/data/with_outliers")) %>%
lapply(read_csv) %>%
bind_rows
#compile all the csv files to make one dataframe of all data
df <- list.files(path=setwd("~/Documents/GitHub/CSIA_lab_work/data/with_outliers")) %>%
lapply(read_csv) %>%
bind_rows
#Remove 5AA and REF columns
df <- df[!df$Sample.ID == "5AA",]
df <- df[,1:12]
#####Add Year column ####
year.2digit <- substr(df$Sample.ID, 1, 2)
year <- vector(mode="character")
for(i in 1:length(year.2digit)){
if(year.2digit[i] <= 22){
year[i] <- paste0(20, year.2digit[i])
} else{
year[i] <- paste0(19, year.2digit[i])
}
}
df$Year <- year
df <- df %>% relocate(Year, .before = VAL.mean)
#####Add System column####
sys <- substr(df$Sample.ID, 4, 4)
system <- vector(mode="character")
for(i in 1:length(sys)){
if(sys[i] == "W"){
system[i] <- "Wood"
} else if(sys[i] == "K"){
system[i] <- "Kvichak"
}  else{
system[i] <- "Egegik"
}
}
df$System <- system
df <- df %>% relocate(System, .before = VAL.mean)
#####Add Age column####
df$Age <- substr(df$Sample.ID, 6, 6)
df <- df %>% relocate(Age, .before = VAL.mean)
####Add column of replicates####
df$new.ID <- substr(df$Sample.ID, 1, 6) #new.ID gets rid of R in sample.ID
rep <- substr(df$Sample.ID, 8, 8)
df$rep <- substr(df$Sample.ID, 8, 8)
#function to average duplicate/replicates and replace in data file with new averages
#run this function as many times as replicates there are
rm_duplicates <- function(df, ID, Year, System, Age){
a <- subset(df, new.ID == ID)
b <- as.data.frame(a[,6:15])
vec <- vector(mode="numeric", length=10)
for(i in 1:10){
vec[i] <- mean(as.numeric(b[,i]))
}
c <- append(c(1, ID, Year, System, Age),c(vec, ID, 0))
norep <- df[!df$new.ID==ID,]
new.data <- rbind(norep, c)
print(new.data)
}
df <- rm_duplicates(df = df, ID = "01_E_3", Year = "2001", System = "Egegik", Age = "3")
df <- rm_duplicates(df = df, ID = "22_K_3", Year = "2022", System = "Kvichak", Age = "3")
df <- rm_duplicates(df = df, ID = "22_W_3", Year = "2022", System = "Wood", Age = "3")
df <- rm_duplicates(df = df, ID = "13_W_2", Year = "2013", System = "Wood", Age = "2")
df <- rm_duplicates(df = df, ID = "13_W_3", Year = "2013", System = "Wood", Age = "3")
df <- rm_duplicates(df = df, ID = "04_E_2", Year = "2004", System = "Egegik", Age = "2")
df <- rm_duplicates(df = df, ID = "10_W_2", Year = "2010", System = "Wood", Age = "2")
df <- rm_duplicates(df = df, ID = "22_E_2", Year = "2022", System = "Egegik", Age = "2")
df <- rm_duplicates(df = df, ID = "74_W_2", Year = "1974", System = "Wood", Age = "2")
df <- rm_duplicates(df = df, ID = "89_K_2", Year = "1989", System = "Kvichak", Age = "2")
#check to see if there are any duplicate samples left
anyDuplicated(df$new.ID)
#remove the last two columns
data <- df
data <- as.data.frame(data[,1:15])
#define beta and TDF values, this can be changed later if necessary
beta <- 3.4 #commonly used constant
TDF <- 7.06 #from Lerner et al 2020
#make an empty data frame to fill with Sample.ID and trophic position
tp <- data.frame(matrix(nrow = length(data$Sample.ID), ncol = 2))
tp <-setNames(tp, c("Sample.ID","Trophic.Position"))
#for loop to calculate trophic position and fill data frame
for(i in 1:length(data$Sample.ID)){
tp[i,2] <- 1 + ((as.numeric(data$GLU.mean[i])-as.numeric(data$PHE.mean[i])-beta)/TDF)
tp[i,1] <- data$Sample.ID[i]
}
#combine new data frame with original
data <- cbind(data, tp)
data <- data[, 3:17]
#write new file
file.name <- "~/Documents/GitHub/CSIA_lab_work/data/final/data.csv"
write.csv(data, file.name)
#this is an r script to do some basic data visualization of the cleaned data
#at this point the data should be drift corrected, compiled, and had all
#duplicates and replicates removed and averaged
rm(list =ls())
setwd("~/Documents/GitHub/CSIA_lab_work/data/final")
library(dplyr)
library(readr)
library(ggplot2)
library(ggpubr)
#read in the main data file
data <- read.csv(file="data.csv")
#scatter plot of year vs isotope signature
PHE.all <- ggplot(data = data, aes(Year, PHE.mean, color = System)) +
geom_point(size = 3, alpha = 0.7)
Wood <- data[data$System =="Wood",]
Kvichak <- data[data$System =="Kvichak",]
Egegik <- data[data$System =="Egegik",]
#plots of age vs isotope sig in the different river systems
ggplot(data = Wood, aes(Year, PHE.mean, color = as.character(Age))) +
geom_point(size = 3, alpha = 0.7)
ggplot(data = Kvichak, aes(Year, PHE.mean, color = as.character(Age))) +
geom_point(size = 3, alpha = 0.7)
ggplot(data = Egegik, aes(Year, PHE.mean, color = as.character(Age))) +
geom_point(size = 3, alpha = 0.7)
#main graphs with trend line
PHE.all <- ggplot(data = data, aes(x = Year, y = PHE.mean, color = System)) +
geom_point(size = 3, alpha = 0.7) +
labs(title = "Phenylalanine (source) Signature Through Time",
x = "Year",
y = "PHE d15N") +
theme(axis.title = element_text(size = 15),
plot.title = element_text(size=16)) +
geom_vline(xintercept=1977, linetype ="dashed") +
geom_vline(xintercept=1998, linetype ="dashed") +
geom_smooth(aes(group=1))
PHE.all <- ggplot(data = data, aes(x = Year, y = PHE.mean, color = System)) +
geom_point(size = 3, alpha = 0.7) +
labs(title = "Phenylalanine (source) Signature Through Time",
x = "Year",
y = "PHE d15N") +
theme(axis.title = element_text(size = 15),
plot.title = element_text(size=16)) +
geom_vline(xintercept=1977, linetype ="dashed") +
geom_vline(xintercept=1998, linetype ="dashed") +
geom_smooth(aes(group=1))
PHE.W <- ggplot(data = Wood, aes(x = Year, y = PHE.mean)) +
geom_point(size = 3, alpha = 0.7, color = "#619CFF") +
labs(title = "Wood",
x = "Year",
y = "PHE d15N") +
theme(axis.title = element_text(size = 15),
plot.title = element_text(size=16)) +
geom_vline(xintercept=1977, linetype ="dashed") +
geom_vline(xintercept=1998, linetype ="dashed") +
geom_smooth(aes(group=1))
PHE.all
PHE.W
GLU.all <- ggplot(data = data, aes(x = Year, y = GLU.mean, color = System)) +
geom_point(size = 3, alpha = 0.7) +
labs(title = "Glutamic Acid (trophic) Signature Through Time",
x = "Year",
y = "GLU d15N") +
theme(axis.title = element_text(size = 15),
plot.title = element_text(size=16)) +
geom_vline(xintercept=1977, linetype ="dashed") +
geom_vline(xintercept=1998, linetype ="dashed") +
geom_smooth(aes(group=1))
GLU.all
trophic.all <- ggplot(data = data, aes(x = Year, y = Trophic.Position, color = System)) +
geom_point(size = 3, alpha = 0.7) +
labs(title = "Trophic Position",
x = "Year",
y = "Trophic Position") +
theme(axis.title = element_text(size = 15),
plot.title = element_text(size=16)) +
geom_vline(xintercept=1977, linetype ="dashed") +
geom_vline(xintercept=1998, linetype ="dashed") +
geom_smooth(aes(group=1))
trophic.al
trophic.all
