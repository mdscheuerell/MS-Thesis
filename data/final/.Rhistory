AIC.di.process <- 2 * (process.di + 2)
#calculate AIC for density dependent
AIC.dd.process <- 2 * (process.dd + 3)
#DAIC calculations
AIC.di - AIC.dd
#calculate AIC for density dependent
AIC.dd.process <- 2 * (process.dd + 3)
#DAIC calculations
AIC.di.process - AIC.dd.process
#DAIC calculations
AIC.dd.process - AIC.di.process
#### Observation Error Model ####
nt.obs <- wa_wolf$Abundance
#### Observation Error Model ####
nt.obs <- harborseals$abundance
#density dependent
obs.dd.nll <- function(pars, nt.obs) {
r <- pars[1]
N1 <- pars[2]
K <- pars[3]
nt <- rep(NA, length(nt.obs))
nt[1] <- N1
for(i in 2:length(nt)){
nt[i] <- nt[i - 1] + r * nt[i - 1] * (1 - (nt[i - 1]/K))
}
nll <- -sum(dpois(x = nt.obs, lambda = nt, log = TRUE))
return(nll)
}
start.pars.dd <- c(0.25, 4000, 4000)
obs.dd.fit <- optim(par = start.pars.dd,
fn = obs.dd.nll,
nt.obs = nt.obs,
method = "BFGS") #density independent, observation based model
obs.dd <- obs.dd.fit$value
obs.dd
#density independent
obs.di.nll <- function(pars, nt.obs) {
r <- pars[1]
N1 <- pars[2]
nt <- rep(NA, length(nt.obs))
nt[1] <- N1
for(i in 2:length(nt)){
nt[i] <- nt[i - 1] + r * nt[i - 1]
}
nll <- -sum(dpois(x = nt.obs, lambda = nt, log = TRUE))
return(nll)
}
start.pars.di <- c(0.25, 4000, 4000)
start.pars.di <- c(0.25, 4000)
start.pars.di <- c(0.25, 4000)
obs.di.fit <- optim(par = start.pars.di,
fn = obs.di.nll,
nt.obs = nt.obs,
method = "BFGS") #density independent, observation based model
obs.di <- obs.di.fit$value
obs.di
#calculate AIC for density independent
AIC.di.obs <- 2 * (obs.di + 2)
#calculate AIC for density dependent
AIC.dd.obs <- 2 * (obs.dd + 3)
#DAIC calculations
AIC.dd.obs - AIC.di.obs
#DAIC calculations
AIC.di.obs - AIC.dd.obs
obs.dd.nll(start.pars.di, nt.obs)
obs.dd.nll(start.pars.di, nt.obs)
obs.di.nll(start.pars.di, nt.obs)
start.pars.di <- c(1, 4000)
obs.di.nll(start.pars.di, nt.obs)
obs.di.nll(start.pars.di, nt.obs)
start.pars.di <- c(1, 4000)
obs.di.fit <- optim(par = start.pars.di,
fn = obs.di.nll,
nt.obs = nt.obs,
method = "BFGS") #density independent, observation based model
obs.di <- obs.di.fit$value
obs.di
#calculate AIC for density independent
AIC.di.obs <- 2 * (obs.di + 2)
#calculate AIC for density dependent
AIC.dd.obs <- 2 * (obs.dd + 3)
#DAIC calculations
AIC.di.obs - AIC.dd.obs
obs.di.fit <- optim(par = start.pars.di,
fn = obs.di.nll,
nt.obs = nt.obs,
method = "BFGS") #density independent, observation based model
obs.di
start.pars.di <- c(0.25, 4000)
obs.di.fit <- optim(par = start.pars.di,
fn = obs.di.nll,
nt.obs = nt.obs,
method = "BFGS") #density independent, observation based model
obs.di <- obs.di.fit$value
obs.di
obs.di.fit <- optim(par = start.pars.di,
fn = obs.di.nll,
nt.obs = nt.obs,
method = "BFGS") #density independent, observation based model
obs.di.fit <- optim(par = start.pars.di,
fn = obs.di.nll,
nt.obs = nt.obs,
method = "BFGS") #density independent, observation based model
obs.di <- obs.di.fit$value
#calculate AIC for density independent
AIC.di.obs <- 2 * (obs.di + 2)
#calculate AIC for density dependent
AIC.dd.obs <- 2 * (obs.dd + 3)
#DAIC calculations
AIC.di.obs - AIC.dd.obs
#density dependent
obs.dd.nll <- function(pars, nt.obs) {
r <- pars[1]
N1 <- pars[2]
K <- pars[3]
nt <- rep(NA, length(nt.obs))
nt[1] <- N1
for(i in 2:length(nt)){
nt[i] <- nt[i - 1] + r * nt[i - 1] * (1 - (nt[i - 1]/K))
}
nll <- -sum(dpois(x = nt.obs, lambda = nt, log = TRUE))
return(nll)
}
start.pars.dd <- c(0.25, 4000, 8000)
obs.dd.fit <- optim(par = start.pars.dd,
fn = obs.dd.nll,
nt.obs = nt.obs,
method = "BFGS") #density independent, observation based model
obs.dd <- obs.dd.fit$value
obs.dd
#calculate AIC for density independent
AIC.di.obs <- 2 * (obs.di + 2)
#calculate AIC for density dependent
AIC.dd.obs <- 2 * (obs.dd + 3)
#DAIC calculations
AIC.di.obs - AIC.dd.obs
process.dd.fit
process.dd.fit$par[1]
nt.hat <- rep(NA, length(nt))
#show the fits
r <- process.dd.fit$par[1]
N0 <- process.dd.fit$par[2]
K <- process.dd.fit$par[3]
nt.hat <- rep(NA, length(nt))
nt.hat
nt.hat[1] <- N0 + r * N0 * (1 - (N0/K))
nt.hat
for(i in 2:length(nt)){
nt.hat[i] <- nt[i-1] + r * nt[i-1] * (1 - (nt[i-1]/K))
}
nt.hat.dd <- rep(NA, length(nt))
nt.hat.dd[1] <- N0 + r * N0 * (1 - (N0/K))
for(i in 2:length(nt)){
nt.hat.dd[i] <- nt[i-1] + r * nt[i-1] * (1 - (nt[i-1]/K))
}
plot(x = nt.hat.dd,
y = nt)
plot(x = nt.hat.dd,
y = nt)
abline(lm(nt ~ nt.hat.dd), col = "red")
plot(x = harborseals$year,
y = nt.obs)
obs.di.fit
#showing data as plots
r <- obs.di.fit$par[1]
N1 <- obs.di.fit$par[2]
nt <- rep(NA, length(nt.obs))
nt[1] <- N1
for(i in 2:length(nt)){
nt[i] <- nt[i - 1] + r * nt[i - 1]
}
nt
plot(x = harborseals$year,
y = nt.obs)
lines(nt)
?lines
plot(x = harborseals$year,
y = nt.obs)
lines(x = harborseals$year,
y = nt, col = "red")
#showing data as plots
r.di <- obs.di.fit$par[1]
N1.di <- obs.di.fit$par[2]
nt.di <- rep(NA, length(nt.obs))
nt.di[1] <- N1.di
for(i in 2:length(nt)){
nt.di[i] <- nt.di[i - 1] + r.di * nt.di[i - 1]
}
proc.di.plot <- plot(x = harborseals$year,
y = nt.obs)
lines(x = harborseals$year,
y = nt.di, col = "red")
obs.dd.fit
obs.dd.fit$par[1]
r.dd <- obs.dd.fit$par[1]
N1.dd <- obs.dd.fit$par[2]
K.dd <- obs.dd.fit$par[3]
nt.dd <- rep(NA, length(nt.obs))
nt.dd[1] <- N1
for(i in 2:length(nt.dd)){
nt.dd[i] <- nt.dd[i - 1] + r.dd * nt.dd[i - 1] * (1 - (nt.dd[i - 1]/K.dd))
}
process.plot <- plot(x = harborseals$year,
y = nt.obs)
lines(x = harborseals$year,
y = nt.di, col = "red")
lines(x = harborseals$year,
y = nt.dd, col = "blue")
legend("topright",
legend = c("Density Independent", "Density Dependent"),
col = c("red", "blue"),
lty = 1,
cex = 1.2)
legend("topleft",
legend = c("Density Independent", "Density Dependent"),
col = c("red", "blue"),
lty = 1,
cex = 1.2)
process.plot <- plot(x = harborseals$year,
y = nt.obs)
lines(x = harborseals$year,
y = nt.di, col = "red")
lines(x = harborseals$year,
y = nt.dd, col = "blue")
legend("topleft",
legend = c("Density Independent", "Density Dependent"),
col = c("red", "blue"),
lty = 1,
cex = 1.2)
process.plot <- plot(x = harborseals$year,
y = nt.obs,
xlab = "Year", ylab = "Population")
lines(x = harborseals$year,
y = nt.di, col = "red")
lines(x = harborseals$year,
y = nt.dd, col = "blue")
legend("topleft",
legend = c("Density Independent", "Density Dependent"),
col = c("red", "blue"),
lty = 1,
cex = 1.2)
observation.plot <- plot(x = harborseals$year,
y = nt.obs,
xlab = "Year", ylab = "Population")
lines(x = harborseals$year,
y = nt.di, col = "red")
lines(x = harborseals$year,
y = nt.dd, col = "blue")
legend("topleft",
legend = c("Density Independent", "Density Dependent"),
col = c("red", "blue"),
lty = 1,
cex = 1.2)
setwd("~/Documents/GitHub/CSIA_lab_work/data/final")
data <- read.csv(file = "data.csv")
#load packages
library(changepoint)
#visualize
library(ggplot2)
ggplot(data, aes(x = Year,
y = PHE.mean)) +
geom_point(size = 3, alpha = 0.7)
# Getting the data in a format that will work to create a time series object
# Convert the "Year" column to a factor to ensure correct ordering
data$Year <- factor(data$Year, levels = rev(unique(data$Year)))
# Pivot the data to wide format to create separate columns for each river and age combination
library(tidyr)
data_wide <- pivot_wider(data, names_from = System, values_from = PHE.mean)
# Create data frames for each of the river systems
Eg <- data_wide[, c("Egegik", "Year",
"Trophic.Position", "Age")]
Kvi <- data_wide[, c("Kvichak", "Year",
"Trophic.Position", "Age")]
Wood <- data_wide[, c("Wood", "Year",
"Trophic.Position", "Age")]
# Get rid of years from other systems
Eg <- as.data.frame(Eg[!is.na(Eg$Egegik), ])
Kvi <- as.data.frame(Kvi[!is.na(Kvi$Kvichak), ])
Wood <- as.data.frame(Wood[!is.na(Wood$Wood), ])
# Add NAs where they are missing
# This function inserts a new row at row "r" while shifting the rest of the data frame down
insertRow <- function(existingDF, newrow, r) {
existingDF[seq(r+1,nrow(existingDF)+1),] <- existingDF[seq(r,nrow(existingDF)),]
existingDF[r,] <- newrow
existingDF
}
#### Running function for all missing rows for Egegik ####
newrow <- c(NA, "2019", NA, "3")
Eg <- insertRow(Eg, newrow, r = 3)
newrow <- c(NA, "2016", NA, "3")
Eg <- insertRow(Eg, newrow, r = 5)
newrow <- c(NA, "1992", NA, "3")
Eg <- insertRow(Eg, newrow, r = 21)
newrow <- c(NA, "1986", NA, "3")
Eg <- insertRow(Eg, newrow, r = 25)
newrow <- c(NA, "1983", NA, "2")
Eg <- insertRow(Eg, newrow, r = 27)
newrow <- c(NA, "1983", NA, "3")
Eg <- insertRow(Eg, newrow, r = 27)
newrow <- c(NA, "1980", NA, "2")
Eg <- insertRow(Eg, newrow, r = 29)
newrow <- c(NA, "1980", NA, "3")
Eg <- insertRow(Eg, newrow, r = 30)
newrow <- c(NA, "1974", NA, "3")
Eg <- insertRow(Eg, newrow, r = 33)
newrow <- c(NA, "1965", NA, "3")
Eg <- insertRow(Eg, newrow, r = 39)
#### Running function for all missing rows for Kvichak ####
newrow <- c(NA, "2016", NA, "3")
Kvi <- insertRow(Kvi, newrow, r = 5)
newrow <- c(NA, "2010", NA, "3")
Kvi <- insertRow(Kvi, newrow, r = 9)
newrow <- c(NA, "2007", NA, "3")
Kvi <- insertRow(Kvi, newrow, r = 11)
newrow <- c(NA, "1998", NA, "3")
Kvi <- insertRow(Kvi, newrow, r = 17)
newrow <- c(NA, "1995", NA, "3")
Kvi <- insertRow(Kvi, newrow, r = 19)
newrow <- c(NA, "1993", NA, "3")
Kvi <- insertRow(Kvi, newrow, r = 21)
newrow <- c(NA, "1989", NA, "3")
Kvi <- insertRow(Kvi, newrow, r = 23)
newrow <- c(NA, "1986", NA, "2")
Kvi <- insertRow(Kvi, newrow, r = 25)
newrow <- c(NA, "1986", NA, "3")
Kvi <- insertRow(Kvi, newrow, r = 25)
newrow <- c(NA, "1983", NA, "3")
Kvi <- insertRow(Kvi, newrow, r = 27)
newrow <- c(NA, "1980", NA, "3")
Kvi <- insertRow(Kvi, newrow, r = 29)
newrow <- c(NA, "1977", NA, "3")
Kvi <- insertRow(Kvi, newrow, r = 31)
newrow <- c(NA, "1974", NA, "3")
Kvi <- insertRow(Kvi, newrow, r = 33)
newrow <- c(NA, "1968", NA, "3")
Kvi <- insertRow(Kvi, newrow, r = 37)
newrow <- c(NA, "1965", NA, "3")
Kvi <- insertRow(Kvi, newrow, r = 39)
#### Running function for all missing rows for Wood ####
newrow <- c(NA, "2019", NA, "3")
Wood <- insertRow(Wood, newrow, r = 3)
newrow <- c(NA, "2010", NA, "3")
Wood <- insertRow(Wood, newrow, r = 9)
newrow <- c(NA, "2007", NA, "3")
Wood <- insertRow(Wood, newrow, r = 11)
newrow <- c(NA, "1998", NA, "3")
Wood <- insertRow(Wood, newrow, r = 17)
newrow <- c(NA, "1984", NA, "3")
Wood <- insertRow(Wood, newrow, r = 27)
newrow <- c(NA, "1980", NA, "3")
Wood <- insertRow(Wood, newrow, r = 29)
newrow <- c(NA, "1974", NA, "3")
Wood <- insertRow(Wood, newrow, r = 33)
newrow <- c(NA, "1965", NA, "3")
Wood <- insertRow(Wood, newrow, r = 39)
View(data)
# Average PHE across all ages and systems (should have one data point per year)
data[c(113,114), 2] = "1968" #changing the two 1967s to 1968s to have consistent spacing of years
data[c(79,80), 2] = "1983"
data[c(61,62), 2] = "1992"
library(dplyr)
avg_data_all <- data %>%
group_by(Year) %>%
summarise(avg_PHE = mean(PHE.mean, na.rm = TRUE))
print(avg_data_all)
plot(avg_data_all)
plot(avg_data_all, pch = 16)
View(avg_data_all)
plot(avg_data_all, pch = 1)
# Convert data to a time series object
ts_data <- ts(avg_data_all$avg_PHE,
start = avg_data_all$Year[1],
end = avg_data_all$Year[length(avg_data_all$Year)],
frequency = 1)
print(ts_data)
plot(ts_data)
# Perform change point analysis using the 'cpt.mean' function
cpt_result <- cpt.mean(ts_data)
# Plot the change point analysis results
plot(cpt_result, cpt.col = "blue")
summary(cpt_result)
# Average PHE across all systems with only age 2
age.2 <- data[data$Age == "2",]
View(age.2)
avg_data_2 <- age.2 %>%
group_by(Year) %>%
summarise(PHE.mean = mean(PHE.mean, na.rm = TRUE))
View(avg_data_2)
# Convert data to a time series object
ts_data_2 <- ts(avg_data_2$avg_PHE,
start = avg_data_2$Year[1],
end = avg_data_2$Year[length(avg_data_2$Year)],
frequency = 1)
# Convert data to a time series object
ts_data_2 <- ts(avg_data_2$PHE.mean,
start = avg_data_2$Year[1],
end = avg_data_2$Year[length(avg_data_2$Year)],
frequency = 1)
plot(ts_data_2)
ggplot(data, aes(x = Year,
y = PHE.mean)) +
geom_point(size = 3, alpha = 0.7)
plot(ts_data_2)
# Perform change point analysis using the 'cpt.mean' function
cpt_result_2 <- cpt.mean(ts_data_2)
# Plot the change point analysis results
plot(cpt_result_2, cpt.col = "blue")
summary(cpt_result)
plot(ts_data)
# Average PHE across all systems with only age 2
age.3 <- data[data$Age == "3",]
View(age.3)
library(dplyr)
avg_data_3 <- age.3 %>%
group_by(Year) %>%
summarise(PHE.mean = mean(PHE.mean, na.rm = TRUE))
plot(avg_data_3)
View(Wood)
Wood.all <- Wood %>%
group_by(Year) %>%
summarise(PHE.mean = mean(PHE.mean, na.rm = TRUE))
Wood.all <- Wood %>%
group_by(Year) %>%
summarise(PHE.mean = mean(Wood, na.rm = TRUE))
Wood.all
Wood
Wood.all <- Wood %>%
group_by(Year) %>%
summarise(PHE = mean(Wood, na.rm = TRUE))
View(Wood.all)
# Scale the data so the variance is 1 and mean is 0
set.seed(1)
m1 <- c(rnorm(100,0,1), rnorm(100,5,1))
m1.amoc <- cpt.mean(ml)
cpts(m1.amoc)
# Scale the data so the variance is 1 and mean is 0
set.seed(1)
m1 <- c(rnorm(100,0,1), rnorm(100,5,1))
m1
m1.amoc <- cpt.mean(ml)
m1.amoc <- cpt.mean(m1)
cpts(m1.amoc)
ts_2_scale <- cpt.mean(as.vector(scale(ts_data_2)))
cpts(ts_2_scale)
# Scale the data so the variance is 1 and mean is 0
ts_1_scale <- cpt.mean(as.vector(scale(ts_data)))
cpts(ts_1_scale)
scale(ts_data)
ts_1_scale
cpts(ts_1_scale)
cpts(ts_1_scale)
plot(ts_1_scale)
plot(ts_2_scale)
# Plot the change point analysis results
plot(ts_1_scale, cpt.col = "blue")
summary(ts_1_scale)
# Plot the change point analysis results
plot(ts_2_scale, cpt.col = "blue")
summary(ts_2_scale)
cpt.var(ts_1_data, method = 'PELT', pentalty = "Manual")
cpt.var(ts_1_data, method = 'PELT')
cpt.var(ts_data, method = 'PELT')
cpt.mean(ts_data, method = 'PELT')
# Scale the data so the variance is 1 and mean is 0 and do CP analysis
ts_1_scale <- cpt.mean(as.vector(scale(ts_data)), method = "PELT")
# Plot the change point analysis results
plot(ts_1_scale, cpt.col = "blue")
?cpt.mean
# Scale the data so the variance is 1 and mean is 0 and do CP analysis
ts_1_scale <- cpt.mean(as.vector(scale(ts_data)), method = "SegNeigh")
# Scale the data so the variance is 1 and mean is 0 and do CP analysis
ts_1_scale <- cpt.mean(as.vector(scale(ts_data)), method = "BinSeg")
# Plot the change point analysis results
plot(ts_1_scale, cpt.col = "blue")
# Scale the data so the variance is 1 and mean is 0 and do CP analysis
ts_1_scale <- cpt.mean(as.vector(scale(ts_data)), method = "PELT")
# Convert data to a time series object
ts_data <- ts(avg_data_all$avg_PHE,
start = avg_data_all$Year[1],
end = avg_data_all$Year[length(avg_data_all$Year)],
frequency = 1)
plot(ts_data)
View(avg_data_all)
Wood.all
View(avg_data_2)
setwd("~/Documents/GitHub/CSIA_lab_work/data/final")
data <- read.csv(file = "data.csv")
#load packages
library(changepoint)
#visualize
library(ggplot2)
ggplot(data, aes(x = Year,
y = PHE.mean)) +
geom_point(size = 3, alpha = 0.7)
# Getting the data in a format that will work to create a time series object
# Convert the "Year" column to a factor to ensure correct ordering
data$Year <- factor(data$Year, levels = rev(unique(data$Year)))
# Pivot the data to wide format to create separate columns for each river and age combination
library(tidyr)
data_wide <- pivot_wider(data, names_from = System, values_from = PHE.mean)
# Create data frames for each of the river systems
Eg.all <- data_wide[, c("Egegik", "Year",
"Trophic.Position", "Age")]
Kvi.all <- data_wide[, c("Kvichak", "Year",
"Trophic.Position", "Age")]
Wood.all <- data_wide[, c("Wood", "Year",
"Trophic.Position", "Age")]
# Get rid of years from other systems
Eg.all <- as.data.frame(Eg[!is.na(Eg$Egegik), ])
Kvi.all <- as.data.frame(Kvi[!is.na(Kvi$Kvichak), ])
Wood.all <- as.data.frame(Wood[!is.na(Wood$Wood), ])
View(Eg.all)
